model:
  num_problems : 1000
  num_agent_runs : 1000
  model_training_steps : 100
  history_len: 25
  epochs : 10
  lr : 0.01

  
problem : 
  train : 'MNIST' #options:['MNIST', 'Gaussian', 'Noisy']
  test : 'MNIST' #options:['MNIST', 'Gaussian', 'Noisy']

policy:
  model: 'DQN' # options:['DQN', 'PPO']  info: DQN for hard method, PPO for soft method.
  exploration_fraction : 0.1
  optimization_mode : 'hard' # options:['soft', 'hard']

environment:
  reward_system : "inverse" # options:['opposite', threshold, 'inverse', 'lookahead']  # info: Lookahead only for hard method.
  optimizer_storing_method : "state_dict" # options:['dict', optimizer_class']
